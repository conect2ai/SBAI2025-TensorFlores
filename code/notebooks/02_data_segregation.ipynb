{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data Segregation and Preprocessing for CO2 Emissions Modeling**\n",
        "\n",
        "## **1. Introduction**\n",
        "\n",
        "This notebook is the second step in our project to model CO2 emissions. Building upon the exploratory data analysis (EDA), this script focuses on preparing the data for the modeling phase. The key processes covered here include:\n",
        "* Loading the cleaned dataset versioned by Weights & Biases (Wandb).\n",
        "* Scaling the numerical features to a common range.\n",
        "* Splitting the dataset into training and testing sets.\n",
        "* Versioning the final, processed datasets back to Wandb for use in model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. Library Imports**\n",
        "\n",
        "We begin by importing the necessary Python libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for a cleaner output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# To run this notebook, you need a Wandb account and an API key.\n",
        "# You can create a file named my_key.py with the line: WANDB_KEY = 'your_api_key_here'\n",
        "# and then uncomment the line below.\n",
        "from my_key import WANDB_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* **wandb**: For interacting with the Weights & Biases platform, managing experiments, and handling data artifacts.\n",
        "* **os**: To interact with the operating system, primarily for handling file paths.\n",
        "* **pandas**: For data manipulation using its powerful DataFrame structures.\n",
        "* **sklearn.model_selection.train_test_split**: A function to split arrays or matrices into random train and test subsets.\n",
        "* **sklearn.preprocessing.MinMaxScaler**: A tool to scale features to a given range, typically [0, 1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Initialization of Weights & Biases (Wandb)**\n",
        "\n",
        "A new Wandb run is initiated to log this data segregation and preprocessing job. This ensures that every step of our machine learning pipeline is tracked and reproducible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\thomm\\_netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthommasflores\u001b[0m (\u001b[33mthommasflores-ufrn\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\thomm\\OneDrive\\Documents\\SBAI-TensorFores-2025\\code\\notebooks\\wandb\\run-20250727_023626-ios1x1cx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/thommasflores-ufrn/SBAI%202025/runs/ios1x1cx' target=\"_blank\">sage-wind-1453</a></strong> to <a href='https://wandb.ai/thommasflores-ufrn/SBAI%202025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/thommasflores-ufrn/SBAI%202025' target=\"_blank\">https://wandb.ai/thommasflores-ufrn/SBAI%202025</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/thommasflores-ufrn/SBAI%202025/runs/ios1x1cx' target=\"_blank\">https://wandb.ai/thommasflores-ufrn/SBAI%202025/runs/ios1x1cx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Log in to Wandb using your API key.\n",
        "# Make sure to replace 'your_api_key_here' with your actual key or use the my_key.py file.\n",
        "wandb.login(key=WANDB_KEY)\n",
        "\n",
        "# Initialize a new Wandb run. We define a specific job_type for clarity.\n",
        "run = wandb.init(project=\"SBAI 2025\", job_type=\"data-segregation\", save_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **4. Loading the Cleaned Dataset**\n",
        "\n",
        "Instead of reading from a local CSV file, we retrieve the cleaned dataset directly from Wandb. We use the `use_artifact` method to pull the latest version of our `clean_dataset`, ensuring that we are working with the correct data from the previous EDA step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned dataset loaded successfully from Wandb artifact.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CO2 (g/s) [estimated maf]</th>\n",
              "      <th>intake_pressure</th>\n",
              "      <th>intake_temperature</th>\n",
              "      <th>rpm</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.809921</td>\n",
              "      <td>26.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1568.0</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.796942</td>\n",
              "      <td>57.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1582.0</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.199995</td>\n",
              "      <td>69.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1600.0</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.226761</td>\n",
              "      <td>38.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1625.0</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.756202</td>\n",
              "      <td>24.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1586.0</td>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CO2 (g/s) [estimated maf]  intake_pressure  intake_temperature     rpm  \\\n",
              "0                   0.809921             26.0                54.0  1568.0   \n",
              "1                   1.796942             57.0                53.0  1582.0   \n",
              "2                   2.199995             69.0                53.0  1600.0   \n",
              "3                   1.226761             38.0                54.0  1625.0   \n",
              "4                   0.756202             24.0                54.0  1586.0   \n",
              "\n",
              "   speed  \n",
              "0   43.0  \n",
              "1   43.0  \n",
              "2   43.0  \n",
              "3   44.0  \n",
              "4   45.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Use the 'latest' alias to get the most recent version of the artifact.\n",
        "artifact = run.use_artifact(artifact_or_name=\"clean_dataset:latest\")\n",
        "\n",
        "# Download the artifact's contents to a local directory.\n",
        "# Wandb manages the path and returns it.\n",
        "path = artifact.download()\n",
        "\n",
        "# Construct the full path to the CSV file within the downloaded directory.\n",
        "csv_file_path = os.path.join(path, 'emission_clean.csv')\n",
        "\n",
        "# Load the data into a pandas DataFrame.\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(\"Cleaned dataset loaded successfully from Wandb artifact.\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5. Feature Scaling**\n",
        "\n",
        "Machine learning algorithms often perform better when numerical input features are scaled to a standard range. This prevents features with larger scales from dominating the model. Here, we use `MinMaxScaler` to transform our data into a [0, 1] range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data scaled successfully. Displaying descriptive statistics of the scaled data:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CO2 (g/s) [estimated maf]</th>\n",
              "      <th>intake_pressure</th>\n",
              "      <th>intake_temperature</th>\n",
              "      <th>rpm</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10230.000000</td>\n",
              "      <td>10230.000000</td>\n",
              "      <td>10230.000000</td>\n",
              "      <td>10230.000000</td>\n",
              "      <td>10230.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.164184</td>\n",
              "      <td>0.408729</td>\n",
              "      <td>0.449839</td>\n",
              "      <td>0.261053</td>\n",
              "      <td>0.379858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.166003</td>\n",
              "      <td>0.252708</td>\n",
              "      <td>0.224329</td>\n",
              "      <td>0.170076</td>\n",
              "      <td>0.284558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.046714</td>\n",
              "      <td>0.197531</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.118919</td>\n",
              "      <td>0.126582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.074022</td>\n",
              "      <td>0.382716</td>\n",
              "      <td>0.464286</td>\n",
              "      <td>0.267027</td>\n",
              "      <td>0.379747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.263370</td>\n",
              "      <td>0.543210</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.385495</td>\n",
              "      <td>0.582278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CO2 (g/s) [estimated maf]  intake_pressure  intake_temperature  \\\n",
              "count               10230.000000     10230.000000        10230.000000   \n",
              "mean                    0.164184         0.408729            0.449839   \n",
              "std                     0.166003         0.252708            0.224329   \n",
              "min                     0.000000         0.000000            0.000000   \n",
              "25%                     0.046714         0.197531            0.285714   \n",
              "50%                     0.074022         0.382716            0.464286   \n",
              "75%                     0.263370         0.543210            0.571429   \n",
              "max                     1.000000         1.000000            1.000000   \n",
              "\n",
              "                rpm         speed  \n",
              "count  10230.000000  10230.000000  \n",
              "mean       0.261053      0.379858  \n",
              "std        0.170076      0.284558  \n",
              "min        0.000000      0.000000  \n",
              "25%        0.118919      0.126582  \n",
              "50%        0.267027      0.379747  \n",
              "75%        0.385495      0.582278  \n",
              "max        1.000000      1.000000  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize the scaler.\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Apply the scaler to the DataFrame.\n",
        "# fit_transform calculates the scaling parameters (min, max) and applies the transformation.\n",
        "df_scaled_values = scaler.fit_transform(df)\n",
        "\n",
        "# The output of the scaler is a NumPy array. We convert it back to a pandas DataFrame,\n",
        "# preserving the original column names.\n",
        "df_scaled = pd.DataFrame(df_scaled_values, columns=df.columns.tolist())\n",
        "\n",
        "print(\"Data scaled successfully. Displaying descriptive statistics of the scaled data:\")\n",
        "display(df_scaled.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown by the descriptive statistics, all features now have a minimum value of 0 and a maximum value of 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **6. Data Splitting (Train-Test Split)**\n",
        "\n",
        "To evaluate our model's performance on unseen data, we split the dataset into two parts: a training set and a testing set.\n",
        "* **Training Set (80%)**: Used to train the machine learning model.\n",
        "* **Testing Set (20%)**: Used to evaluate the final performance of the trained model.\n",
        "\n",
        "We set a `random_state` to ensure that the split is reproducible every time the code is run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data split into training and testing sets.\n",
            "Training set shape: (8184, 5)\n",
            "Testing set shape: (2046, 5)\n"
          ]
        }
      ],
      "source": [
        "# Split the scaled DataFrame into training and testing sets.\n",
        "# test_size=0.2 means 20% of the data will be used for testing.\n",
        "train_df, test_df = train_test_split(df_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Data split into training and testing sets.\")\n",
        "print(f\"Training set shape: {train_df.shape}\")\n",
        "print(f\"Testing set shape: {test_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **7. Versioning the Processed Datasets**\n",
        "\n",
        "Finally, we save the training and testing sets as new artifacts in Wandb. This is a crucial step for maintaining a clear data lineage. The next step in our pipeline (model training) can now pull these specific artifacts, ensuring a seamless and organized workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train and test CSV files saved locally.\n",
            "Training data artifact created and logged.\n",
            "Testing data artifact created and logged.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sage-wind-1453</strong> at: <a href='https://wandb.ai/thommasflores-ufrn/SBAI%202025/runs/ios1x1cx' target=\"_blank\">https://wandb.ai/thommasflores-ufrn/SBAI%202025/runs/ios1x1cx</a><br> View project at: <a href='https://wandb.ai/thommasflores-ufrn/SBAI%202025' target=\"_blank\">https://wandb.ai/thommasflores-ufrn/SBAI%202025</a><br>Synced 6 W&B file(s), 0 media file(s), 6 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20250727_023626-ios1x1cx\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a local directory to store the split data files.\n",
        "os.makedirs(\"split_data\", exist_ok=True)\n",
        "train_path = \"split_data/train.csv\"\n",
        "test_path = \"split_data/test.csv\"\n",
        "\n",
        "# Save the DataFrames to local CSV files.\n",
        "train_df.to_csv(train_path, index=False)\n",
        "test_df.to_csv(test_path, index=False)\n",
        "print(\"Train and test CSV files saved locally.\")\n",
        "\n",
        "# Create a new Wandb artifact for the training dataset.\n",
        "train_artifact = wandb.Artifact(\"train_dataset\", type=\"dataset\", description=\"Training data for the CO2 emission model.\")\n",
        "train_artifact.add_file(train_path)\n",
        "wandb.log_artifact(train_artifact)\n",
        "print(\"Training data artifact created and logged.\")\n",
        "\n",
        "# Create a new Wandb artifact for the testing dataset.\n",
        "test_artifact = wandb.Artifact(\"test_dataset\", type=\"dataset\", description=\"Testing data for the CO2 emission model.\")\n",
        "test_artifact.add_file(test_path)\n",
        "wandb.log_artifact(test_artifact)\n",
        "print(\"Testing data artifact created and logged.\")\n",
        "\n",
        "# Finish the Wandb run to save all logs and artifacts.\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **8. Conclusion**\n",
        "\n",
        "This notebook has successfully prepared the data for model training. We have loaded the cleaned data, scaled its features, split it into training and testing sets, and versioned these final datasets as artifacts in Weights & Biases. The next logical step is to train a predictive model using the `train_dataset` artifact."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
